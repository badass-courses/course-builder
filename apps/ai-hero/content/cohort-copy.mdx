LLMs are powerful.

Especially for the kinds of "fuzzy" tasks that are similar but not identical. The kinds of tasks that make work tiring, annoying, or difficult: Gather all this info up and find the related parts. Break down and prioritize this request. Prep for this meeting, then follow up after. This task got lost; when did we drop this from our conversations across email, Slack, Github comments? Now please file this ticket.

It's not that LLMs can do all the work *for* you, but they can be an incredible support that empowers you to focus on the work only *you* can do. Just like the very best executive assistant.

But generic chatbots (the big commercial ones) don't really give you access to that power. And they don't offer particularly high-quality output, either. They simply can't; they try to be all things to all people. Millions of users can't all have a custom experience crafted just for them. The context windows can only be so big. You can only load so much data. Prompts can only get you so far. They're not configurable. You can't tinker with the guts. It's a black box.

The thing is, these chatbots are not "the LLM" itself, they're an **interface** between you and the model. 

And it's that interface, the **system**, that matters most. When you use a big name chatbot, it's the **system** that makes all the choices about what data to pass to the model and when, how to shape and handle the responses, what to remember, and more. 

Choices you don't know about, can't find out about, and certainly can't change. 

All the custom prompts in the world can't overcome the power of their system. 

<ThemeImage urls={{dark: "https://res.cloudinary.com/total-typescript/image/upload/v1762846712/cohorts/cohort-ytorn/tcgggfreg4fwifkeh0qh.png", light: "https://res.cloudinary.com/total-typescript/image/upload/v1762846712/cohorts/cohort-ytorn/fcuhwkmrf4cichzicb4b.png"}} width={678} height={132} />

When you want to fully grasp the power of **bespoke** AI, you've gotta build your own **system**: a tool that uses *your* data, learns *your* preferences, remembers what *you* tell it, interacts with *your* tools, and feeds all that into state of the art models.

And, despite what you may have heard, you **don't** need to train your own custom model! 

In fact, the model itself is almost irrelevant! 

The **system** is where the overwhelming majority of *smarts* are: the data handling, the context management, the tools. 

**You can build your *own* system.** One that learns from you *and* remembers. One that uses complex and sophisticated techniques to search, interpret, and analyze your data. One that *you* tune and control. 

**_Your_ system can absolutely *trounce* a commercial chatbot in terms of function and fit for purpose.**

When you roll your own system, your very own bespoke **assistant**, you can unlock the true power of LLMs in three ways:

1. **Retrieval**. You give your assistant access to your own data (heaps of it, instead of the little bit you can paste into a textbox) which it provides intelligently to the model underneath, as-needed

2. **Memory**. You give your assistant a persistent "memory" (so it can remember statements, preferences, interactions between sessions) which it uses to "remind" the model of just the most salient facts, helping it tailor its outputs to you

3. **Agents + Human-in-the-Loop.** You build agents that can access tools and APIs for your favorite apps and services, and use your assistant (your *system*) to delegate this access, controlled by human sanity-checking, to the model

That's the makings of an *ideal* personal assistant. Or, frankly, any kind of custom LLM-powered tool. 

And you don't need a data center, or a bunch of GPUs, or a machine learning degree to build it.

You can use off-the-shelf models, tools, and AI engineering patterns to achieve amazing results.

And in my new cohort-based workshop, that's exactly what you'll learn how to do.

## Here's how you build your own bespoke personal assistant

First, you'll gather your data and data sources.

Then you'll prepare the data in the best way: chunking, ensembling, re-ranking.

Next, you'll program your assistant to know when and how to provide the right data to your model of choice using specific retrieval techniques like BM25, semantic search, and RRF, with query rewriting for optimization. 

Now it's time to make it smart. You'll implement memory so it'll *remember* your preferences and feedback, and learn and improve every time you use it.

Reliability comes next: You'll test and evaluate its outputs programmatically, with custom scorers, to ensure quality and consistency.

Finally, once you have these core functions down, you can expand it endlessly with new data sources and the power to use your favorite existing tools via APIs and MCP servers. 

These steps work together to create a shockingly powerful and useful assistant. 

**You'll do all this over just 5 days when you enroll Build A Personal Assistant in TypeScript.**

You'll learn theory, best practices, tools, *and* you'll learn through building. 

You'll graduate knowing how to add data, memory, context, control, safety checks and tooling to a stock LLM model to make it smarter, more effective, and more reliable. And, of course, *personal*. 

That’s the power of modern AI engineering! 

## **Enroll in Build a Personal Assistant in TypeScript today**

It's an exciting and action-packed 5-day virtual cohort course running December 8 through December 14.

You can attend from anywhere; learning is totally async. 

You'll use my custom course platform to work through snappy videos and coding exercises. Both of which are yours to keep, along with the code repo for the course.

You'll be invited to join our exclusive Discord to soak up the energy of learning along with us, socialize, and ask questions. I'll be available!

I'll host live Q&A sessions on Monday, Wednesday and Friday (Dec 8, 10, 12) at X TIMES. Tune in live, or submit your question in advance for the recording, which you'll receive. You'll get transcripts, too.

AI SDK v5 is a pre-requisite, but I've got you covered: When you enroll today, you'll get instant access to my popular _AI SDK v5 Crash Course_ for free. You can hit the ground running when the cohort starts on December 8.

The only thing you need to bring is TypeScript experience, and a thirst for knowledge.

By the end of **Build a Personal Assistant in TypeScript**, you'll have gained two incredibly valuable things:

1. A functional assistant that can load your (properly chunked) data, and help you extract all kinds of value from it; one that learns from you, remembers what you tell it, and asks for your human confirmation before taking destructive steps; and of course the LLM-agnostic code you've written in AI SDK v5… **and** 

2. All the skills you need to take that easily extensible foundation to plan and build any *other* kind of custom LLM-powered tool you can imagine, for work or play.

Just think of what this kind of power-up can do for your personal efficiency, your work, and your career!

For the 5-day cohort course and all the lessons and exercises you get to keep, AI SDK v5 Crash Course ($149 value), the livestream Q&As, recordings, transcripts, and exclusive Discord access, the price is <PricingInline type="original" />.
<HasDiscount>

**But I'm offering a deep discount when you enroll early.**

It's a steal for ~~<PricingInline type="original" />~~ <PricingInline type="discounted" /> if you enroll by <DiscountDeadline />!
</HasDiscount>
<HasPurchased productSlug="ai-sdk-v5-crash-course">

Owners of the AI SDK v5 Crash Course: You save an additional $99!
</HasPurchased>
## Here's what you'll be learning, doing, and building each day

### Pre-Class: Learn AI SDK v5

AI SDK v5 is the toolkit that makes modern AI tool development in TypeScript possible, and you'll be heavily using it every day of this course.

When you enroll in **Build a Personal Assistant in TypeScript**, you'll receive a free copy of my popular AI SDK v5 Crash Course. It's got everything you need to learn in short, fun lessons and exercises, at your own pace.

### Day 1: Learn Retrieval

The magic of *bespoke* begins with your data, both how you prepare it and how you retrieve it again at the right moment in the future. Retrieval includes a set of tools, design patterns, and best practices that help unlock the power of off-the-shelf LLMs to really let work with your own data, *far* beyond pasting your data into a chat textbox. 

On Day 1, you'll learn:

* core retrieval techniques, and the many approaches at your fingertips
* how to compare two of the most common types of retrieval techniques (BM25 and embeddings) to enable keyword and semantic searching through your data
* how to use RRF (Reciprocal Rank Fusion) to combine and score mixed search results
* how to use query rewriting to get the most out of your retrieval techniques

### Day 2: Make it Retrieve

After you learn the fundamentals of data preparation and retrieval techniques in Day 1, you’ll get a chance to practice them on “real” data. Initially you’ll provide some synthetic prepared data based on a real inbox before you try it on your inbox or another personal data set.

On Day 2, you'll: 

* dive into chunking techniques, learning how to handle documents of any size while preserving the structure of your data
* work with rerankers to optimize your retrieval further to find the most relevant chunks 
* use agentic retrieval to give tools to the model, and let it combine different searches in powerful ways to find answers
* use metadata-first retrieval techniques to save on tokens, so the model finds the most efficient path to the information it needs

### Day 3: Make it Remember

The next thing that makes *your* assistant bespoke is *learning from your personal choices, actions and preferences*. What you do with it, what you like and don't like, what feedback you give it. 

On Day 3, you'll: 

* build memory saving & retention techniques
* learn how to handle infinite-length conversations with working memory
* learn the difference between semantic and episodic memory, and implement both
* efficiently retrieve the right memories at the right moment
* all while carefully managing your context window!

### Day 4: Make it Reliable

The biggest thing that makes an assistant *useful* is knowing you can trust the output it generates. You want to feel confident that its responses don’t just sound good, but that they’re consistent, accurate, and useful. Evals are the main tool you can use to *build* trust, by verifying.

On Day 4, you'll:

* learn how to evaluate tool calling agents
* use A/B testing to dial in the perfect parameters (and model!) for your system
* build LLM-as-a-judge scorers for evaluating tools
* learn how to evaluate retrieval and memory

### Day 5: Make it Safe

Finally, you'll want to make your assistant *power* by giving it the ability to use tools, like APIs, to get data and execute on plans. But safely. You'll learn how to program your assistant to ask you, "is that right?" and "should I do this?" before executing.

On Day 5, you'll extend your personal assistant's abilities by:

* giving your agent the ability to contact any MCP server (example: fetch live emails)
* use human-in-the-loop techniques to make sure you're fully in control
* customizing your agent to ask clarifying questions and relay plans

### After Class: Practice, Train, Expand

Your learning doesn't have to stop on December 14th, when the cohort officially closes.

The lessons, exercise, and repo are yours to keep. You can revisit the lessons and code any time to refresh your memory or to use as a reference, or dive deeper with any bonus exercises you didn't get to. 

You'll have a working knowledge of AI engineering practices like retrieval, evals, human-in-the-loop, and tool calling… so you can continue learning from other advanced material.

By the end of your 5-day sprint, you'll know how to train your assistant to learn new tasks for you, like daily status updates, spotting trends, and identifying missed opportunities, *and* how to use evals and other tools to ensure it does those tasks correctly. You'll be able to expand its capabilities and reach using APIs and MCP.

You'll be able to train it to do potentially destructive tasks (like setting or deleting calendar entries) *safely*, by confirming with you, the human, at each step.

And of course your assistant is just the beginning. 

You can use these same skills to develop **any** kind of bespoke AI **system**. To work with virtually *any* model.

For just <HasDiscount fallback={<PricingInline type="original" />}><PricingInline type="discounted" /></HasDiscount>, you'll gain the skills, knowledge, and *experience* to create compelling, custom AI tools for yourself, and for your company, clients, and customers. 